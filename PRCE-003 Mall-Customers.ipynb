from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("MallCustomers").getOrCreate()
df = spark.read.csv("Mall_Customers.csv", header=True, inferSchema=True)
df.show(5)
+----------+------+---+------------------+----------------------+
|CustomerID| Genre|Age|Annual Income (k$)|Spending Score (1-100)|
+----------+------+---+------------------+----------------------+
|         1|  Male| 19|                15|                    39|
|         2|  Male| 21|                15|                    81|
|         3|Female| 20|                16|                     6|
|         4|Female| 23|                16|                    77|
|         5|Female| 31|                17|                    40|
+----------+------+---+------------------+----------------------+
only showing top 5 rows
df.groupBy("Genre").avg("Spending Score (1-100)", "Annual Income (k$)").show()
+------+---------------------------+-----------------------+
| Genre|avg(Spending Score (1-100))|avg(Annual Income (k$))|
+------+---------------------------+-----------------------+
|Female|         51.526785714285715|                  59.25|
|  Male|          48.51136363636363|      62.22727272727273|
+------+---------------------------+-----------------------+
